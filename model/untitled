

### READING THE DATA
## The data is made of a star file, in ReLion format: https://relion.readthedocs.io/en/release-3.1/Reference/Conventions.html for a reference. 
## This star file contains all the parameters you need to project your structure into an image:
##  - The parameters of the CTF, which corresponds to a flipping and scaling of the power spectrum of the image: https://www.youtube.com/watch?v=mPynoF2j6zc
##	- The pose of the protein on each image: a set of euler angles for the rotation and a set of 2d translation vectors (always 0 in our case).
##
##Associated to the starfile is an mrc file containing the set of 2d images.
##
## The following class inherits the torch.Dataset class. You can instantiate this class with a specific dataset.

import os
import torch
import mrcfile
import numpy as np
from time import time
from torch.utils.data import Dataset
import torchvision.transforms.functional as tvf
from pytorch3d.transforms import euler_angles_to_matrix

class ImageDataSet(Dataset):
    def __init__(self, apix, side_shape, particles_df, particles_path, down_side_shape=None, down_method="interp"):
        """
        Create a dataset of images and poses
        :param apix: float, size of a pixel in Å.
        :param side_shape: integer, number of pixels on each side of a picture. So the picture is a side_shape x side_shape array
        :param particle_df: particles dataframe coming from a star file
        :particles_path: string, path to the folder containing the mrcs files. It is appended to the path present in the star file.
        :param down_side_shape: integer, number of pixels of the downsampled images. If no downampling, set down_side_shape = side_shape. 
        """
        self.side_shape = side_shape
        self.down_method = down_method
        self.apix = apix
        self.particles_path = particles_path
        self.particles_df = particles_df
        print(particles_df.columns)
        #Reading the euler angles and turning them into rotation matrices. 
        euler_angles_degrees = particles_df[["rlnAngleRot", "rlnAngleTilt", "rlnAnglePsi"]].values
        euler_angles_radians = euler_angles_degrees*np.pi/180
        poses = euler_angles_to_matrix(torch.tensor(euler_angles_radians, dtype=torch.float32), convention="ZYZ")
        #Transposing because ReLion has a clockwise convention, while we use a counter-clockwise convention.
        poses = torch.transpose(poses, dim0=-2, dim1=-1)

        #Reading the translations. ReLion may express the translations divided by apix. So we need to multiply by apix to recover them in Å
        if "rlnOriginXAngst" in particles_df:
            shiftX = torch.from_numpy(np.array(particles_df["rlnOriginXAngst"], dtype=np.float32))
            shiftY = torch.from_numpy(np.array(particles_df["rlnOriginYAngst"], dtype=np.float32))
        else:
            shiftX = torch.from_numpy(np.array(particles_df["rlnOriginX"] * self.apix, dtype=np.float32))
            shiftY = torch.from_numpy(np.array(particles_df["rlnOriginY"] * self.apix, dtype=np.float32))

        self.poses_translation = torch.tensor(torch.vstack([shiftY, shiftX]).T, dtype=torch.float32)   
        self.poses = poses
        assert self.poses_translation.shape[0] == self.poses.shape[0], "Rotation and translation pose shapes are not matching !"
        #assert torch.max(torch.abs(poses_translation)) == 0, "Only 0 translation supported as poses"
        print("Dataset size:", self.particles_df, "apix:",self.apix)
        print("Normalizing training data")

        #If a downsampling is wanted, recompute the new apix and set the new down_side_shape
        self.down_side_shape = side_shape
        if down_side_shape is not None:
            self.down_side_shape = down_side_shape
            self.down_apix = self.side_shape * self.apix /self.down_side_shape

    def standardize(self, images, device="cpu"):
        return (images - self.avg_image.to(device))/self.std_image.to(device)

    def __len__(self):
        return self.particles_df.shape[0]

    def __getitem__(self, idx):
        """
        Return a batch of true images, as 2d array !
        # return: the set of indexes queried for the batch, the corresponding images as a torch.tensor((batch_size, side_shape, side_shape)), 
        # the corresponding poses rotation matrices as torch.tensor((batch_size, 3, 3)), the corresponding poses translations as torch.tensor((batch_size, 2))
        # NOTA BENE: the convention for the rotation matrix is left multiplication of the coordinates of the atoms of the protein !!
        """
        particles = self.particles_df.iloc[idx]
        try:
            mrc_idx, img_name = particles["rlnImageName"].split("@")
            mrc_idx = int(mrc_idx) - 1
            mrc_path = os.path.join(self.particles_path, img_name)
            with mrcfile.mmap(mrc_path, mode="r", permissive=True) as mrc:
                if mrc.data.ndim > 2:
                    proj = torch.from_numpy(np.array(mrc.data[mrc_idx])).float() #* self.cfg.scale_images
                else:
                    # the mrcs file can contain only one particle
                    proj = torch.from_numpy(np.array(mrc.data)).float() #* self.cfg.scale_images

            # get (1, side_shape, side_shape) proj
            if len(proj.shape) == 2:
                proj = proj[None, :, :]  # add a dummy channel (for consistency w/ img fmt)
            else:
                assert len(proj.shape) == 3 and proj.shape[0] == 1  # some starfile already have a dummy channel

            if self.down_side_shape != self.side_shape:
                if self.down_method == "interp":
                    proj = tvf.resize(proj, [self.down_side_shape, ] * 2, antialias=True)
                #elif self.down_method == "fft":
                #    proj = downsample_2d(proj[0, :, :], self.down_side_shape)[None, :, :]
                else:
                    raise NotImplementedError            

            proj = proj[0]

        except Exception as e:
            print(f"WARNING: Particle image {img_name} invalid! Setting to zeros.")
            print(e)
            proj = torch.zeros(self.down_side_shape, self.down_side_shape)


        return idx, proj, self.poses[idx], self.poses_translation[idx]/self.down_apix




### Reading the base structure

import dataclasses

import gemmi
import numpy as np
import biotite.structure as struc
from biotite.structure.io.pdb import PDBFile

# careful about the order
AA_ATOMS = ("CA", )
NT_ATOMS = ("C1'", )


def get_num_electrons(atom_arr):
    return np.sum(np.array([gemmi.Element(x).atomic_number for x in atom_arr.element]))

##This class contains informations about the Polymer at hand. Note that we act only on the residue level, not on the atom level. We consider that a residue is located 
#at his c_\alpha coordinates
#The attributes of interest are: coord, containing the coordinates of the protein structure and num_electron that contains the average electron per atom for each #residue. This number is used as the amplitude for each residue in the function projecting the structure into an image.
# You also want to use the from_pdb object that will create a Polymer instance from a .pdb file, and to_pdb that creates a .pdb file from an Polymer instance.

@dataclasses.dataclass
class Polymer:
    chain_id: np.ndarray
    res_id: np.ndarray
    res_name: np.ndarray
    coord: np.ndarray
    atom_name: np.ndarray
    element: np.ndarray
    num_electron: np.ndarray

    def __init__(self, num):
        self.chain_id = np.empty(num, dtype="U4")
        self.res_id = np.zeros(num, dtype=int)
        self.res_name = np.empty(num, dtype="U3")
        self.coord = np.zeros((num, 3), dtype=np.float32)
        self.atom_name = np.empty(num, dtype="U6")
        self.element = np.empty(num, dtype="U2")
        self.num_electron = np.zeros(num, dtype=int)

    def __setitem__(self, index, kwargs):
        assert set(kwargs.keys()).issubset(f.name for f in dataclasses.fields(self))
        for k, v in kwargs.items():
            getattr(self, k)[index] = v

    def __getitem__(self, index):
        return {f.name: getattr(self, f.name)[index] for f in dataclasses.fields(self)}

    def __len__(self):
        return len(self.chain_id)

    @property
    def num_amino_acids(self):
        return np.sum(np.isin(self.atom_name, AA_ATOMS))

    @property
    def num_nucleotides(self):
        return np.sum(np.isin(self.atom_name, NT_ATOMS))

    @property
    def num_chains(self):
        return len(np.unique(self.chain_id))

    @classmethod
    def from_atom_arr(cls, atom_arr, filter_aa=True):
        assert isinstance(atom_arr, struc.AtomArray)

        nt_arr = atom_arr[struc.filter_nucleotides(atom_arr)]
        aa_arr = atom_arr
        if filter_aa:
            aa_arr = atom_arr[struc.filter_amino_acids(atom_arr)]


        num = 0
        if len(aa_arr) > 0:
            num += struc.get_residue_count(aa_arr)
        if len(nt_arr) > 0:
            for res in struc.residue_iter(nt_arr):
                valid_atoms = set(res.atom_name).intersection(NT_ATOMS)
                if len(valid_atoms) <= 0:
                    raise UserWarning(f"Nucleotides doesn't contain {' or '.join(NT_ATOMS)}.")
                else:
                    num += len(valid_atoms)
        meta = cls(num)

        def _update_res(tmp_res, kind="aa"):
            nonlocal pos

            if kind == "aa":
                using_atom_names = AA_ATOMS
                filtered_res = tmp_res[struc.filter_peptide_backbone(tmp_res)]
                ##### REMOVING THE FILTER HERE !!!
                filtered_res = tmp_res
            elif kind == "nt":
                using_atom_names = NT_ATOMS
                filtered_res = tmp_res
            else:
                raise NotImplemented

            valid_atom_names = set(tmp_res.atom_name).intersection(using_atom_names)
            for select_atom_name in valid_atom_names:
                meta[pos] = {
                    "chain_id": tmp_res.chain_id[0],
                    "res_id": tmp_res.res_id[0],
                    "res_name": tmp_res.res_name[0],
                    "coord": filtered_res[filtered_res.atom_name == select_atom_name].coord,
                    "atom_name": select_atom_name,
                    "element": filtered_res[filtered_res.atom_name == select_atom_name].element[0],
                    "num_electron": get_num_electrons(tmp_res) // len(valid_atom_names)
                }
                pos += 1

        def _update(tmp_arr, kind="aa"):
            nonlocal pos
            for chain in struc.chain_iter(tmp_arr):
                for tmp_res in struc.residue_iter(chain):
                    _update_res(tmp_res, kind)

        pos = 0

        if len(aa_arr) > 0:
            _update(aa_arr, kind="aa")
        if len(nt_arr) > 0:
            _update(nt_arr, kind="nt")

        ## REMOVING ASSERT HERE !
        #assert pos == num
        return meta

    @classmethod
    def from_pdb(cls, file_path, filter_aa=True):
        f = PDBFile.read(file_path)
        atom_arr_stack = f.get_structure()
        if atom_arr_stack.stack_depth() > 1:
            print("PDB file contains more than 1 models, select the 1st model")
        atom_arr = atom_arr_stack[0]
        return Polymer.from_atom_arr(atom_arr, filter_aa)

    def to_pdb(self, file_path):
        """
        Save the Polymer structure to pdb
        file_path: str, path to save the pdb file
        """
        file = PDBFile()
        file.set_structure(self.to_atom_arr())
        file.write(file_path)

    def to_atom_arr(self):
        num = len(self)
        atom_arr = struc.AtomArray(num)
        atom_arr.coord = self.coord

        for f in dataclasses.fields(self):
            if f.name != "coord" and f.name in atom_arr.get_annotation_categories():
                atom_arr.set_annotation(f.name, getattr(self, f.name))
        # atom_arr.atom_name[atom_arr.atom_name == "R"] = "CB"
        return atom_arr

    def center_structure(self, apix):
        """
        Centers the structure to -apix/2 so that the structure is centered on images following the EMAN2 grid convention.
        apix: float
        """
        center_of_mass = np.mean(self.coord, axis=0)[None, :]
        self.coord -= center_of_mass
        self.coord -= apix/2

    def translate_structure(self, translation_vector):
        """
        Translate the structure by the translation vector
        translation_vector: np.array(None, 3)
        """
        self.coord += translation_vector




### Corrupting the data with the CTF.
## The following code defines a CTF object that has a compute_ctf method used to compute the ctf corresponding to the images in this specific batch. These ctf can be 
## subsequently used to corrupt the predicted images 


import torch
import starfile
import numpy as np
import matplotlib.pyplot as plt


class CTF(torch.nn.Module):
	"""
	Class describing the ctf, built from starfile
	"""
	def __init__(self, side_shape, apix, defocusU, defocusV, defocusAngle, voltage, sphericalAberration, amplitudeContrastRatio, phaseShift=None ,scalefactor = None,
		bfactor= None, device="cpu"):
		"""
		side shape: number of pixels on a side.
		apix: size of a pixel in Å.
		defocusU: defocusU.
		defocusV: defocusV.
		defocusAngle: defocus angle in degrees.
		voltage: accelerating voltage in keV.
		sphericalAberration: spherical aberration in mm.
		AmplitudeContrastRatio: amplitude contrat ratio.
		phaseShift: phase shift in degrees.
		scalefactor: scalefactor.
		bfactor: bfactor.
		device: str, device to use.
		"""
		super().__init__()
		if phaseShift is None:
			phaseShift = torch.zeros(defocusU.shape, dtype=torch.float32, device=device)
		else:
			phaseShift = torch.tensor(phaseShift, dtype=torch.float32, device=device)

		if scalefactor is None:
			scalefactor = torch.ones(defocusU.shape, dtype=torch.float32, device=device)
		else:
			scalefactor = torch.tensor(scalefactor, dtype=torch.float32, device=device)

		if bfactor is None:
			bfactor = torch.zeros(defocusU.shape, dtype=torch.float32, device=device)
		else:
			bfactor = torch.tensor(bfactor, dtype=torch.float32, device=device)


		saved_args = locals()
		assert len(set({len(val) for arg_name,val in saved_args.items() if arg_name not in ["self", "__class__", "device"]})) == 1, "CTF values do not have the same shape."
		assert len(set(side_shape)) == 1, "All images must have the same number of pixels"
		assert len(set(apix)) == 1, "All images must have the same apix"
		self.register_buffer("Npix", torch.tensor(side_shape, dtype=torch.float32, device=device)[:, None])
		self.register_buffer("Apix", torch.tensor(apix, dtype=torch.float32, device=device)[:, None])
		self.register_buffer("dfU", torch.tensor(defocusU[:, None], dtype=torch.float32, device=device))
		self.register_buffer("dfV", torch.tensor(defocusV[:, None], dtype=torch.float32, device=device))
		self.register_buffer("dfang", torch.tensor(defocusAngle[:, None], dtype=torch.float32, device=device))
		self.register_buffer("volt", torch.tensor(voltage[:, None], dtype=torch.float32, device=device))
		self.register_buffer("cs", torch.tensor(sphericalAberration[:, None], dtype=torch.float32, device=device))
		self.register_buffer("w", torch.tensor(amplitudeContrastRatio[:, None], dtype=torch.float32, device=device))
		self.register_buffer("phaseShift", phaseShift[:, None])
		self.register_buffer("scalefactor", scalefactor[:, None])
		self.register_buffer("bfactor", bfactor[:, None])
		self.npix = int(side_shape[0])
		self.apix = apix[0]
		#In this stack, freqs[0, :] corresponds to constant x values, freqs[:, 0] corresponds to contant y values.
		freqs = (
		    torch.stack(
		        self.meshgrid_2d(-0.5, 0.5, self.npix, endpoint=False),
		        -1,
		    )
		    / self.apix)

		self.freqs = freqs.reshape(-1, 2)
		self.freqs = self.freqs.to(device)
		#In freqs, x is the first coordinate, y is the second and we are in x major
		#ctf = self.compute_ctf(freqs, self.dfU, self.dfV, self.dfang, self.volt, self.cs, self.w, self.phaseShift, None, None)


	@classmethod
	def from_starfile(cls, file, device="cpu", **kwargs):
		"""
		Instantiate a CTF object from a starfile.
		:param file: path to the starfile containing the parameters of the ctf
		:param device: str, path to the starfile.
		"""
		df = starfile.read(file)

		overrides = {}

		#First we find the values of the CTF in the optics block of the star file.
		try:
			side_n_pix = int(df["optics"].loc[0, "rlnImageSize"])
			apix = df["optics"].loc[0, "rlnImagePixelSize"]
		except Exception:
		    assert "side_shape" in kwargs and "apix" in kwargs, "side_shape, apix must be provided."
		    side_n_pix = kwargs["side_shape"]
		    apix = kwargs["apix"]

		if "optics" in df:
		    assert len(df["optics"]) == 1, "Currently only support one optics group."
		    overrides["rlnVoltage"] = df["optics"].loc[0, "rlnVoltage"]
		    overrides["rlnSphericalAberration"] = df["optics"].loc[0, "rlnSphericalAberration"]
		    overrides["rlnAmplitudeContrast"] = df["optics"].loc[0, "rlnAmplitudeContrast"]

		#Second, if there are particles in the file we find defocus U, V and angle for each one of them. Otherwise we just find the 
		#values in the optics block and there is only one ctf. Notte that the CTF parameters in the optics groups have precedence on
		# the ones in the data block.

		if "particles" in df:
			df = df["particles"]

		num = len(df)
		ctf_params = np.zeros((num, 9))
		ctf_params[:, 0] = side_n_pix
		ctf_params[:, 1] = apix
		for i, header in enumerate([
		"rlnDefocusU",
		"rlnDefocusV",
		"rlnDefocusAngle",
		"rlnVoltage",
		"rlnSphericalAberration",
		"rlnAmplitudeContrast",
		"rlnPhaseShift",
		]):
			if header in overrides:
				ctf_params[:, i + 2] = overrides[header]
			else:
				ctf_params[:, i + 2] = df[header].values if header in df else None

		return cls(*ctf_params[:, :8].T, phaseShift=None, device=device)

	def meshgrid_2d(self, lo, hi, n, endpoint=False):
		"""
		Torch-compatible implementation of:
		np.meshgrid(
		        np.linspace(-0.5, 0.5, D, endpoint=endpoint),
		        np.linspace(-0.5, 0.5, D, endpoint=endpoint),
		    )
		Torch doesn't support the 'endpoint' argument (always assumed True)
		and the behavior of torch.meshgrid is different unless the 'indexing' argument is supplied.
		"""
		if endpoint:
		    values = torch.linspace(lo, hi, n)
		else:
		    values = torch.linspace(lo, hi, n + 1)[:-1]

		return torch.meshgrid(values, values, indexing="xy")

	def compute_ctf(self, indexes
		) -> torch.Tensor:
		"""

		This code is based on the cryoDRGN code.
		Compute the 2D CTF

		Input:
		    indexes: torch.tensor(batch_size) of indexes of the images in this batch.
		"""
		# convert units
		volt = self.volt[indexes]
		cs = self.cs[indexes]
		dfu = self.dfU[indexes]
		dfv = self.dfV[indexes]
		dfang = self.dfang[indexes]
		w = self.w[indexes]
		phase_shift = self.phaseShift[indexes]
		bfactor = self.bfactor[indexes]
		scalefactor = self.scalefactor[indexes]

		volt = volt * 1000
		cs = cs * 10 ** 7
		dfang = dfang * np.pi / 180
		phase_shift = phase_shift * np.pi / 180

		# lam = sqrt(h^2/(2*m*e*Vr)); Vr = V + (e/(2*m*c^2))*V^2
		lam = 12.2639 / torch.sqrt(volt + 0.97845e-6 * volt ** 2)
		x = self.freqs[..., 0]
		y = self.freqs[..., 1]
		#Since we take arctan between y and x and not x and y, we are still in x ordering but x is the second coordinate now !
		ang = torch.arctan2(y, x)
		s2 = x ** 2 + y ** 2
		df = 0.5 * (dfu + dfv + (dfu - dfv) * torch.cos(2 * (ang - dfang)))
		gamma = (
		        2 * torch.pi * (-0.5 * df * lam * s2 + 0.25 * cs * lam ** 3 * s2 ** 2)
		        - phase_shift
		)
		ctf = torch.sqrt(1 - w ** 2) * torch.sin(gamma) - w * torch.cos(gamma)
		if scalefactor is not None:
			scalefactor = self.scalefactor[indexes]
			ctf *= scalefactor
		if bfactor is not None:
			bfactor = self.bfactor[indexes]
			ctf *= torch.exp(-bfactor / 4 * s2)


		#But in this project, the images are (y_coords, x_coords), see renderer.project so we transpose:
		ctf = ctf.reshape((len(indexes), self.npix, self.npix))
		return torch.transpose(ctf, dim0=-2, dim1=-1)
  


#### The next function projects a structure into an image.

## First we need a grid object. This gives the coordinates of a line and pixels and voxels.
class BaseGrid(torch.nn.Module):
	"""
	Grid spanning origin, to origin + (side_shape - 1) * voxel_size
	:param side_n_pixels: number of pixels along one axis
	:param voxel_size: size of a voxel in Å.
	"""
	def __init__(self, side_n_pixels, voxel_size, origin=None, device="cpu"):
		super().__init__()
		self.side_n_pixels = side_n_pixels
		self.voxel_size = voxel_size
		if not origin:
			origin = 0

		self.origin = origin

		line_coords = torch.linspace(origin, (side_n_pixels - 1) * voxel_size + origin, side_n_pixels, device=device)
		self.register_buffer("line_coords", line_coords)
		[xx, yy] = torch.meshgrid([self.line_coords, self.line_coords], indexing="ij")
		plane_coords = torch.stack([xx, yy], dim=-1).reshape(-1, 2)
		self.register_buffer("plane_coords", plane_coords)
		self.plane_shape = (self.side_n_pixels, self.side_n_pixels)

		[xx, yy, zz] = torch.meshgrid([self.line_coords, self.line_coords, self.line_coords])
		vol_coords = torch.stack([xx, yy, zz], dim=-1).reshape(-1, 3)
		self.register_buffer("vol_coords", vol_coords)
		self.vol_shape = (self.side_n_pixels, self.side_n_pixels, self.side_n_pixels)



class EMAN2Grid(BaseGrid):
    """EMAN2 style grid.
    origin set to -(side_shape // 2) * voxel_size

    """

    def __init__(self, side_shape, voxel_size, device="cpu"):
        origin = -side_shape // 2 * voxel_size
        super().__init__(side_n_pixels=int(side_shape), voxel_size=voxel_size, origin=origin, device=device)


def project(Gauss_mean, Gauss_sigmas, Gauss_amplitudes, grid):
    """
    Project a volumes represented by a GMM into a 2D images, by integrating along the z axis
    Gauss_mean: torch.tensor(batch_size, N_atoms, 3), location of the atoms.
    Gauss_sigmas: torch.tensor(N_atoms, 1), sigmas used in the Gaussian mode for each atom. 
    Gauss_amplitudes: torch.tensor(N_atoms, 1), amplitudes in front of the exponential term of each mode.
    grid: grid object
    where N_atoms is the number of atoms in the structure.
    return images: torch.tensor(batch_size, N_pix, N_pix)
    """
    sigmas = 2*Gauss_sigmas**2
    sqrt_amp = torch.sqrt(Gauss_amplitudes)
    #Both proj_x and proj_y are (batch_size, N_atoms, N_pix)
    proj_x = torch.exp(-(Gauss_mean[:, :, None, 0] - grid.line_coords[None, None, :])**2/sigmas[None, :, None,  0])*sqrt_amp[None, :, :]
    proj_y = torch.exp(-(Gauss_mean[:, :, None, 1] - grid.line_coords[None, None, :])**2/sigmas[None, :, None, 0])*sqrt_amp[None, :, :]
    images = torch.einsum("b a p, b a q -> b q p", proj_x, proj_y)
    return images



def primal_to_fourier2d(images):
    """
    Computes the fourier transform of the images.
    images: torch.tensor(batch_size, N_pix, N_pix)
    return fourier transform of the images
    """
    r = torch.fft.ifftshift(images, dim=(-2, -1))
    fourier_images = torch.fft.fftshift(torch.fft.fft2(r, dim=(-2, -1), s=(r.shape[-2], r.shape[-1])), dim=(-2, -1))
    return fourier_images

def fourier2d_to_primal(fourier_images):
    """
    Computes the inverse fourier transform
    fourier_images: torch.tensor(batch_size, N_pix, N_pix)
    return fourier transform of the images
    """
    f = torch.fft.ifftshift(fourier_images, dim=(-2, -1))
    r = torch.fft.fftshift(torch.fft.ifft2(f, dim=(-2, -1), s=(f.shape[-2], f.shape[-1])),dim=(-2, -1)).real
    return r

## This function applies the ctf corresponding to the images in the batch.
def apply_ctf(images, ctf, indexes):
    """
    apply ctf to images.
    images: torch.tensor(batch_size, N_pix, N_pix)
    ctf: CTF object
    indexes: torch.tensor(batch_size, type=int)
    return ctf corrupted images
    """
    fourier_images = primal_to_fourier2d(images)
    fourier_images *= ctf.compute_ctf(indexes)
    ctf_corrupted = fourier2d_to_primal(fourier_images)
    return ctf_corrupted
